{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Install swi-prolog"
      ],
      "metadata": {
        "id": "N7sENIvOqPme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swi-prolog"
      ],
      "metadata": {
        "id": "iRh4pmsfp7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System prompt"
      ],
      "metadata": {
        "id": "TPjv7i0vo7L1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E6JRYjVoKwV"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a specialized Prolog code-generating assistant.\n",
        "\n",
        "Your task is to solve math problems by providing a structured answer in two clearly defined sections:\n",
        "\n",
        "1. <reasoning>\n",
        "   - Provide a clear, concise step-by-step explanation of how you arrive at the solution.\n",
        "\n",
        "2. <answer>\n",
        "   - Provide executable Prolog code using constraint logic programming to compute the numeric answer.\n",
        "   - Always start with: ':- use_module(library(clpq)).'\n",
        "   - Define any necessary numeric constants or intermediate values using predicates.\n",
        "   - Final answer should be unified explicitly in solve(X) using curly-brace constraints, without printing commands.\n",
        "\n",
        "Use this XML format strictly:\n",
        "<reasoning>\n",
        "(Your step-by-step reasoning here)\n",
        "</reasoning>\n",
        "<answer>\n",
        ":- use_module(library(clpq)).\n",
        "\n",
        "(Any predicates/constants defined here)\n",
        "\n",
        "solve(X) :-\n",
        "    (Intermediate computations using curly braces)\n",
        "    {X = final constraint logic}.\n",
        "</answer>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "g_QYasvMo9Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import load_dataset\n",
        "import subprocess\n",
        "\n",
        "# ----------------------\n",
        "# Helper Functions\n",
        "# ----------------------\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    try:\n",
        "        start = text.rfind(\"<answer>\")\n",
        "        end = text.rfind(\"</answer>\")\n",
        "        if start == -1 or end == -1 or end < start:\n",
        "            return None\n",
        "        return text[start + len(\"<answer>\"): end].strip()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def execute_prolog_code(prolog_code: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes the given Prolog code in SWI-Prolog, calling solve(X),\n",
        "    and returns the printed solution as a string (e.g., \"12000\").\n",
        "    Returns None if there's an error or no output.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Write the Prolog code to a temporary file\n",
        "        with open(\"temp.pl\", \"w\") as f:\n",
        "            f.write(prolog_code)\n",
        "\n",
        "        # Run SWI-Prolog: load 'temp.pl', call solve(X), print X, then halt\n",
        "        result = subprocess.run(\n",
        "            [\"swipl\", \"-q\", \"-f\", \"temp.pl\", \"-g\", \"solve(X), writeln(X), halt\"],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=5,  # optional: 5-second timeout\n",
        "        )\n",
        "\n",
        "        # If there's any error output, we can check result.stderr or result.returncode\n",
        "        if result.returncode != 0 or not result.stdout:\n",
        "            return None\n",
        "\n",
        "        # result.stdout is whatever got printed by writeln(X)\n",
        "        lines = result.stdout.strip().splitlines()\n",
        "        return lines[-1].strip() if lines else None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error executing Prolog code: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wu0X0EZTog_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess dataset and push to HF"
      ],
      "metadata": {
        "id": "_L2_HFH0o_G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "def get_gsm8k_questions(split=\"train\"):\n",
        "    data = load_dataset('Thomas-X-Yang/gsm8k-prolog')[split]\n",
        "\n",
        "    def map_fn(x):\n",
        "        # Compute the correct numerical result by executing the reference Prolog solution.\n",
        "        numerical_result = execute_prolog_code(x[\"output\"])\n",
        "        return {\n",
        "            \"instruction\": x[\"instruction\"],\n",
        "            \"input\": x[\"input\"],\n",
        "            \"output\": x[\"output\"],\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": f\"{x['instruction']}\\n{x['input']}\"}\n",
        "            ],\n",
        "            # Optionally, you can also append the numerical result to the output field.\n",
        "            \"answer\": x['output'],\n",
        "            \"numerical_result\": str(numerical_result),  # Precomputed numeric result\n",
        "        }\n",
        "\n",
        "    data = data.map(map_fn)\n",
        "    return data\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "print(dataset[0])"
      ],
      "metadata": {
        "id": "akdp4adMonxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and push the dataset to Hugging Face Hub.\n",
        "# Replace \"your_username\" with your HF username and \"hf_your_token\" with your token if needed.\n",
        "dataset.push_to_hub(\"niklasm222/gsm8k-prolog-prover-extended\", token=\"\", private=False)"
      ],
      "metadata": {
        "id": "3OhcPvitoz9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare preprocessed dataset with openai/gsm8k"
      ],
      "metadata": {
        "id": "M1KYux3opHj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ----------------------\n",
        "# Helper Function to extract the final numeric answer from the OpenAI GSM8K \"answer\" column.\n",
        "# ----------------------\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    # Remove commas to facilitate conversion to float.\n",
        "    return text.split(\"####\")[1].replace(\",\", \"\").strip()\n",
        "\n",
        "# ----------------------\n",
        "# Load both datasets\n",
        "# ----------------------\n",
        "# Load gsm8k-prolog-extended dataset (change split as needed)\n",
        "dataset_extended = load_dataset(\"niklasm222/gsm8k-prolog-extended\", split=\"train\")\n",
        "# Load openai/gsm8k dataset (change split as needed)\n",
        "dataset_openai = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
        "\n",
        "# Determine how many samples to compare (using the minimum length)\n",
        "total = min(len(dataset_extended), len(dataset_openai))\n",
        "\n",
        "# ----------------------\n",
        "# Compare numerical_result from gsm8k-prolog-extended with the numeric answer from openai/gsm8k\n",
        "# ----------------------\n",
        "matches = 0\n",
        "differences = []\n",
        "mismatches = []  # List to store mismatched sample details\n",
        "\n",
        "for i in range(total):\n",
        "    # Get the numerical_result from the gsm8k-prolog-extended dataset\n",
        "    ext_val_str = dataset_extended[i][\"numerical_result\"]\n",
        "    try:\n",
        "        ext_val = float(ext_val_str)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping sample {i} from extended dataset due to conversion error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Get the answer text from the openai/gsm8k dataset\n",
        "    openai_answer_text = dataset_openai[i][\"answer\"]\n",
        "    extracted_str = extract_hash_answer(openai_answer_text)\n",
        "    if extracted_str is None:\n",
        "        print(f\"Skipping sample {i} from openai dataset because '####' not found.\")\n",
        "        continue\n",
        "    try:\n",
        "        openai_val = float(extracted_str)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping sample {i} from openai dataset due to conversion error: {e}\")\n",
        "        continue\n",
        "\n",
        "    diff = abs(ext_val - openai_val)\n",
        "    differences.append(diff)\n",
        "    if diff < 1e-6:\n",
        "        matches += 1\n",
        "    else:\n",
        "        # Record mismatched sample details: index, extended value, openai value, and optionally the question\n",
        "        question = dataset_extended[i].get(\"input\", \"N/A\")\n",
        "        mismatches.append({\n",
        "            \"index\": i,\n",
        "            \"question\": question,\n",
        "            \"extended_value\": ext_val,\n",
        "            \"openai_value\": openai_val,\n",
        "            \"difference\": diff\n",
        "        })\n",
        "\n",
        "accuracy = matches / total * 100\n",
        "print(f\"Compared {total} samples. Match accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "if mismatches:\n",
        "    print(\"\\nMismatched Samples:\")\n",
        "    for m in mismatches:\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Index: {m['index']}\")\n",
        "        print(f\"Question: {m['question']}\")\n",
        "        print(f\"Extended Value: {m['extended_value']}\")\n",
        "        print(f\"OpenAI Value: {m['openai_value']}\")\n",
        "        print(f\"Difference: {m['difference']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c52b76dfa9c432faa9a6f4e45e665c9",
            "0e676071c3d4491cbf33726b7b2a3f6d",
            "969c22aad4564951bc2990d49b99b502",
            "e810a807cf2a44fcafb38dba95eb0bd9",
            "ce7e6197ce564ec98925cfbfa95ff1d3",
            "80d238bb776c484a8b24b67d3ad43b01",
            "8010a06504bc44ef872d997adee913cf",
            "929c7a72f019435ca8d98d488b38354c",
            "430db22959bc4a3191e19f2bc0bc972a",
            "5df2aa6459af4dd8b983dd23a4fe385b",
            "ebfd51dd85c24c4cabdfe5376311703c",
            "9c13f174b21841438300de4a3ce3bcd6",
            "f1a01facbe4d405e86c6037e2de81959",
            "116298d7c69e4349889ff18bef063e94",
            "7bfe61b6f65d418594de601affe29f29",
            "711c398c39ef4de5ac0211ae68bb664e",
            "7bf9283497304865bca7ee62cb170cc6",
            "302c78b4bda047dcaef57c3978915d9e",
            "ef37ba3b683445b28ff11128bdd942b7",
            "8d0bac41cd5b460daa4a2ca867e44ac2",
            "2c81db30ef6c4cf7a0ee6c55c42ba105",
            "608e8898afff45579e72e5ead354433c",
            "69e51330c201403e961225c8323bd1f4",
            "fc7b90b8396244b5897923a94bddcdb6",
            "a623707b72ca4604a5f0ed9862575297",
            "2956f88dcc46498eab0c1e1e785a14cc",
            "6e326367d0314771ad523225a3114b5c",
            "429ac45e12554790a967cd2440c94b10",
            "00ef573c54b54d8483a2e47b25a9a1fb",
            "9abf78f477e44c228c591567cb184888",
            "6ac4acee9a9440e0b93a4ffec6046659",
            "26b695617b1342ad8fbe25dc2692c325",
            "f24233302acd4d45bdff97ebf0a489ae",
            "5d1b654fa65c42a6bc174fc7e593a875",
            "9e52defa66b74eadade11db1b8f0250e",
            "78231b7066fd4ee2a882ecac725a19ba",
            "0c8af51500184c4aa1c21f6828658cbd",
            "d07efcd227424714bb7b79318c9c0b61",
            "9566a75d1d3b465bb7fb7ab7f7551097",
            "048ecbfd54fb4aa9919c686d9b239a21",
            "abdc77088853446a931465ebc9e8ea73",
            "5c0eac8c7c9b4866a8e8f64cef3b2b32",
            "d8378762cc674bc0b98ee4f44103298a",
            "812cf52222fa4208995d48287527695c",
            "18e269ef007247afa73d82cda48a41cc",
            "ebdd1c6444e2456481f22e1dd15ceed9",
            "cfe18dd95c1742039777e8e7db02625c",
            "0f45e34617364ef3a53f155f22cb68be",
            "1dc99f69e92e44a4adf2142054f01bee",
            "255eaf1355fe487aab9d7faeb4a3f12f",
            "3766fc42cc5b42808561648747f3210f",
            "c6196c9d58b545f98721b61108fead49",
            "33243a31fe3e4e2e968929355c2ae195",
            "1de181d8cf9a495d81ddb46d6c28a028",
            "ce5277c48bb242d6905527f5a4c1df55",
            "569951692c0b40ef821f735e2d592e61",
            "1cf44bfbe42946968d37e5711b888439",
            "762a3850b12b4787bfc4b9c03e3a83dc",
            "5e4b1378ea16429bbfbc79007b85d582",
            "8f7b808b91ab43ca91f0733080e33c94",
            "be0b417aaf6643b2800376013f261936",
            "cd48c1f228084bcf8b8e8aea88800a7d",
            "c2860556a9f34ac3aba9588be397a7ed",
            "066e895cdfb3474a976988d26f9beb00",
            "4a9259c98cfd4fa8ae1aedcb30fea105",
            "3e3146c066c04d3e942a074a03ba8975",
            "48d48cd4e15f474b8a087544c33509b0",
            "49d216bff3904a52a83f7c0fd47c86c0",
            "bcf44ac62b6049909a5a09100b18c755",
            "ac593cccf0b84b57a1b9572f709a8dd1",
            "3c08a3d8cb9a4c7eabdd040ac7371745",
            "9ca2a32a5caa4abf81ceb3af39d687c7",
            "286fe609cf274732a09fc30b813f5740",
            "9228099dff0a42008b7e30f993381de9",
            "1e0cf556c4714df8a7b7666114ea9ab7",
            "761da307a1dd42059f452e885725fe23",
            "d71d7336a5d84a48ac1dd7fd29ec5747",
            "67984ad55a214237965dae3acb5c6349",
            "7dd4972e189a4031bac9a510f60d11fd",
            "7a1e956ad88e4b4fb85fd9e3b70bcd91",
            "eb0f4bc519914b1898ffbc48a241d54f",
            "b6bb5fba84004f57b376a35b26571077",
            "5450484205384c6ebbc2766baf829273",
            "f458e9f5b53249678a5e8ef1dbc9f88f",
            "8add9629d8184520a7c105766853f768",
            "1eb16806de8f48149020cf4f91836ab5",
            "e5b3a39fcb8d4d82958a19f4a4bfde54",
            "d478a72d2b3c4d958500598fb4ed2303"
          ]
        },
        "id": "TFYvWabLf5EA",
        "outputId": "8feb9ab3-daa8-41b3-9a34-06052f5c857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/536 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c52b76dfa9c432faa9a6f4e45e665c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c13f174b21841438300de4a3ce3bcd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69e51330c201403e961225c8323bd1f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d1b654fa65c42a6bc174fc7e593a875"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18e269ef007247afa73d82cda48a41cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "569951692c0b40ef821f735e2d592e61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d48cd4e15f474b8a087544c33509b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67984ad55a214237965dae3acb5c6349"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compared 7473 samples. Match accuracy: 99.80%\n",
            "\n",
            "Mismatched Samples:\n",
            "----------------------------------------\n",
            "Index: 167\n",
            "Question: Janet filmed a new movie that is 60% longer than her previous 2-hour long movie.  Her previous movie cost $50 per minute to film, and the newest movie cost twice as much per minute to film as the previous movie.  What was the total amount of money required to film Janet's entire newest film?\n",
            "Extended Value: 19200.0\n",
            "OpenAI Value: 1920.0\n",
            "Difference: 17280.0\n",
            "----------------------------------------\n",
            "Index: 228\n",
            "Question: A company has 200 employees.  60% of the employees drive to work.  Of the employees who don't drive to work, half take public transportation. How many more employees drive to work than take public transportation?\n",
            "Extended Value: 80.0\n",
            "OpenAI Value: 40.0\n",
            "Difference: 40.0\n",
            "----------------------------------------\n",
            "Index: 356\n",
            "Question: Students at Highridge High earn 2 points for each correct answer during a quiz bowl If a student correctly answers all the questions in a round, the student is awarded an additional 4 point bonus. They played a total of five rounds each consisting of five questions. If James only missed one question, how many points did he get?\n",
            "Extended Value: 64.0\n",
            "OpenAI Value: 66.0\n",
            "Difference: 2.0\n",
            "----------------------------------------\n",
            "Index: 474\n",
            "Question: A club with 30 members ordered fruit juices. Two-fifths of them ordered lemon juice. One-third of the remaining members ordered mango juice, and the rest ordered orange juice. How many members ordered orange juice?\n",
            "Extended Value: 12.0\n",
            "OpenAI Value: 6.0\n",
            "Difference: 6.0\n",
            "----------------------------------------\n",
            "Index: 1081\n",
            "Question: John has 2 hives of bees.  One of the hives has 1000 bees and produces 500 liters of honey.  The second has 20% fewer bees but each bee produces 40% more honey.  How much honey does he produce?\n",
            "Extended Value: 1060.0\n",
            "OpenAI Value: 2460.0\n",
            "Difference: 1400.0\n",
            "----------------------------------------\n",
            "Index: 1776\n",
            "Question: The teacher told the class that if they averaged at least 75% on their final exam, they could have a pizza party. Everyone took the exam on Monday, except for William, who was allowed to take it on Tuesday. If there are 30 people in the class, and the average before he took the test was a 74%, what score does he have to get to make sure they get to have a pizza party?\n",
            "Extended Value: 104.0\n",
            "OpenAI Value: 94.0\n",
            "Difference: 10.0\n",
            "----------------------------------------\n",
            "Index: 1983\n",
            "Question: Janet buys 3 pounds of broccoli for $4 a pound, 3 oranges for $0.75 each, a cabbage for $3.75, a pound of bacon for $3, and two pounds of chicken for $3 a pound. What percentage of her grocery budget did she spend on meat, rounded to the nearest percent?\n",
            "Extended Value: 33.33333333333333\n",
            "OpenAI Value: 33.0\n",
            "Difference: 0.3333333333333286\n",
            "----------------------------------------\n",
            "Index: 2620\n",
            "Question: Ryan started with 36 tokens at the arcade. Ryan wasted a third of his tokens on Pac-Man, a fourth of his tokens on Candy Crush, and 7 on Ski-ball. Then, his parents bought him seven times as many tokens as he spent on Ski-ball. How many tokens did Ryan end up with?\n",
            "Extended Value: 57.0\n",
            "OpenAI Value: 22.0\n",
            "Difference: 35.0\n",
            "----------------------------------------\n",
            "Index: 2770\n",
            "Question: Robert and Teddy are planning to buy snacks for their friends.  Robert orders five boxes of pizza at $10 each box and ten cans of soft drinks at $2 each. Teddy buys six hamburgers at $3 each and an additional ten cans of soft drinks. How much do they spend in all?\n",
            "Extended Value: 108.0\n",
            "OpenAI Value: 106.0\n",
            "Difference: 2.0\n",
            "----------------------------------------\n",
            "Index: 3263\n",
            "Question: Andy gets a cavity for every 4 candy canes he eats. He gets 2 candy canes from his parents and 3 candy canes each from 4 teachers. Then he uses his allowance to buy 1/7 as many candy canes as he was given. How many cavities does he get from eating all his candy canes?\n",
            "Extended Value: 4.0\n",
            "OpenAI Value: 16.0\n",
            "Difference: 12.0\n",
            "----------------------------------------\n",
            "Index: 3529\n",
            "Question: During one game, a total of 50 people attended a baseball teamâ€™s games. Forty percent and thirty-four percent of the audiences are supporters of the first and second teams, respectively. How many people attended the game did not support either of the teams?\n",
            "Extended Value: 13.0\n",
            "OpenAI Value: 3.0\n",
            "Difference: 10.0\n",
            "----------------------------------------\n",
            "Index: 4099\n",
            "Question: Big Dig Mining Company mines three different types of ore: copper, iron, and nickel. Across all their mines, 10% of their output is nickel, 60% is iron, and the rest is copper. They mine 720 tons of nickel a day. How many tons of copper does Big Dig Mining Company mine daily?\n",
            "Extended Value: 2160.0\n",
            "OpenAI Value: 360.0\n",
            "Difference: 1800.0\n",
            "----------------------------------------\n",
            "Index: 4796\n",
            "Question: In a yard, the number of tanks is five times the number of trucks. If there are 20 trucks in the yard, calculate the total number of tanks and trucks in the yard.\n",
            "Extended Value: 120.0\n",
            "OpenAI Value: 140.0\n",
            "Difference: 20.0\n",
            "----------------------------------------\n",
            "Index: 7182\n",
            "Question: If you double a number and add 5 to the result, then that's 20 more than half of the original number. What's the original number?\n",
            "Extended Value: 10.0\n",
            "OpenAI Value: 4.0\n",
            "Difference: 6.0\n",
            "----------------------------------------\n",
            "Index: 7401\n",
            "Question: Mr. Finnegan has 3 tanks with a capacity of 7000 gallons, 5000 gallons, and 3000 gallons, respectively. If he fills the first tank up to 3/4 full, the second tank with water up to 4/5 of its capacity, and the third tank up to half of its capacity, how many gallons in total are in the tanks?\n",
            "Extended Value: 10750.0\n",
            "OpenAI Value: 10850.0\n",
            "Difference: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updates for indexes in openai/gsm8k"
      ],
      "metadata": {
        "id": "p7jlaGtDg-qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define the new answer texts for each error by index.\n",
        "updates = {\n",
        "    167: \"\"\"The first movie was 2*60=<<2*60=120>>120 minutes\n",
        "So this movie is 120*0.6=<<120*0.6=72>>72 minutes longer\n",
        "So this movie is 120+72=<<120+72=192>>192 minutes\n",
        "It also cost 50*2=$<<50*2=100>>100 per minute to film\n",
        "So it cost 192*100=$<<192*100=19200>>19200\n",
        "#### 19200\"\"\",\n",
        "\n",
        "    228: \"\"\"A company has 200 employees. 60% of the employees drive to work, so 200 * 0.60 = <<200*0.60=120>>120 drive to work.\n",
        "The remaining employees who don't drive are 200 - 120 = <<200-120=80>>80.\n",
        "Of these 80 employees, half take public transportation: 80 * 0.50 = <<80*0.50=40>>40.\n",
        "The difference between those who drive and those who take public transportation is 120 - 40 = <<120-40=80>>80 employees.\n",
        "#### 80\"\"\",\n",
        "\n",
        "    356: \"\"\"If James only missed one question in all five rounds of five questions, he correctly answered 5*5 - 1 = <<5*5-1=24>>24 questions.\n",
        "Before the bonus, James earned 24 * 2 = <<24*2=48>>48 points.\n",
        "Since missing one question disqualifies him from receiving the bonus in that round, he earns the bonus in 5 - 1 = <<5-1=4>>4 rounds.\n",
        "Each bonus round is worth 4 points, so his bonus totals 4 * 4 = <<4*4=16>>16 points.\n",
        "Including his bonus, James scored 48 + 16 = <<48+16=64>>64 points.\n",
        "#### 64\"\"\",\n",
        "\n",
        "    474: \"\"\"Two-fifths of 30 = <<30*2/5=12>>12 members ordered lemon juice.\n",
        "Remaining members = 30 - 12 = <<30-12=18>>18.\n",
        "One-third of the remaining 18 = <<18*1/3=6>>6 members ordered mango juice.\n",
        "Thus, the number of members who ordered orange juice = 18 - 6 = <<18-6=12>>12.\n",
        "#### 12\"\"\",\n",
        "\n",
        "    1081: \"\"\"The first hive has 1000 bees producing 500 liters of honey, so each bee produces 500/1000 = <<500/1000=0.5>>0.5 liters.\n",
        "The second hive has 20% fewer bees than the first hive: 1000 - (20% of 1000) = 1000 - 200 = <<1000-200=800>>800 bees.\n",
        "Each bee in the second hive produces 40% more honey than a bee in the first hive: 0.5 * 1.4 = <<0.5*1.4=0.7>>0.7 liters per bee.\n",
        "Thus, the second hive produces 800 * 0.7 = <<800*0.7=560>>560 liters of honey.\n",
        "The total honey produced is 500 + 560 = <<500+560=1060>>1060 liters.\n",
        "#### 1060\"\"\",\n",
        "\n",
        "    1776: \"\"\"Let x be the score that William needs to achieve.\n",
        "Since there are 30 students in the class, there are 30 - 1 = <<30-1=29>>29 students besides William.\n",
        "The total required score for a 75% average is 30 * 75 = <<30*75=2250>>2250.\n",
        "The total score of the other 29 students is 29 * 74 = <<29*74=2146>>2146.\n",
        "Therefore, William must score at least 2250 - 2146 = <<2250-2146=104>>104.\n",
        "#### 104\"\"\",\n",
        "\n",
        "    2620: \"\"\"Ryan started with 36 tokens.\n",
        "He used 36/3 = <<36/3=12>>12 tokens on Pac-Man.\n",
        "He used 36/4 = <<36/4=9>>9 tokens on Candy Crush.\n",
        "He used 7 tokens on Ski-ball.\n",
        "Total tokens used = 12 + 9 + 7 = <<12+9+7=28>>28.\n",
        "Remaining tokens = 36 - 28 = <<36-28=8>>8 tokens.\n",
        "His parents bought him 7 times the tokens he spent on Ski-ball, which is 7 * 7 = <<7*7=49>>49 tokens.\n",
        "Thus, Ryan ended up with 8 + 49 = <<8+49=57>>57 tokens.\n",
        "#### 57\"\"\",\n",
        "\n",
        "    2770: \"\"\"Five boxes of pizza cost 5 x $10 = $<<5*10=50>>50.\n",
        "Ten cans of soft drinks cost 10 x $2 = $<<10*2=20>>20.\n",
        "So, Robert spends $50 + $20 = $<<50+20=70>>70.\n",
        "Six hamburgers cost 6 x $3 = $<<6*3=18>>18.\n",
        "Ten additional cans of soft drinks cost 10 x $2 = $<<10*2=20>>20.\n",
        "Thus, Teddy spends $18 + $20 = $<<18+20=38>>38.\n",
        "The total amount spent is $70 + $38 = $<<70+38=108>>108.\n",
        "#### 108\"\"\",\n",
        "\n",
        "    3263: \"\"\"First, find how many candy canes Andy receives from his teachers:\n",
        "3 canes/teacher * 4 teachers = <<3*4=12>>12 canes.\n",
        "Then, add the number of candy canes he gets from his parents: 12 + 2 = <<12+2=14>>14 canes.\n",
        "Then, he uses his allowance to buy 1/7 as many candy canes as he was given: 14 / 7 = <<14/7=2>>2 canes.\n",
        "The total number of candy canes is 14 + 2 = <<14+2=16>>16.\n",
        "Since Andy gets a cavity for every 4 candy canes he eats, the number of cavities is 16 / 4 = <<16/4=4>>4.\n",
        "#### 4\"\"\",\n",
        "\n",
        "    3529: \"\"\"Forty percent of 50 = 50 * 0.40 = <<50*0.40=20>>20 supporters for the first team.\n",
        "Thirty-four percent of 50 = 50 * 0.34 = <<50*0.34=17>>17 supporters for the second team.\n",
        "Total supporters = 20 + 17 = <<20+17=37>>37.\n",
        "Thus, the number of people who did not support either team = 50 - 37 = <<50-37=13>>13.\n",
        "#### 13\"\"\",\n",
        "\n",
        "    4099: \"\"\"Let R be the total ore output of the company.\n",
        "Nickel is 10% of the total output. Since Big Dig mines 720 tons of nickel daily,\n",
        "the total ore output is 720 / 0.10 = 7200 tons.\n",
        "Copper constitutes the remainder, i.e., 100 - 10 - 60 = 30% of the output.\n",
        "Thus, the amount of copper mined daily is 7200 * 0.30 = <<7200*0.30=2160>>2160 tons.\n",
        "#### 2160\"\"\",\n",
        "\n",
        "    4796: \"\"\"There are 5 * 20 = <<5*20=100>>100 tanks in the yard.\n",
        "Altogether, there are 100 + 20 = <<100+20=120>>120 trucks and tanks in the yard.\n",
        "#### 120\"\"\",\n",
        "\n",
        "    7182: \"\"\"Let x be the original number.\n",
        "2*x + 5 = 20 + x/2\n",
        "Multiplying both sides by 2: 4*x + 10 = 40 + x\n",
        "Rearranging: 3*x = 30\n",
        "Thus, x = 10\n",
        "#### 10\"\"\",\n",
        "\n",
        "    7401: \"\"\"The capacity of the first tank is 7000 gallons, and if it is filled up to 3/4 full, it carries 3/4*7000 = 5250 gallons.\n",
        "When the second tank is filled up to 4/5 of its capacity, it carries 4/5*5000 = <<4/5*5000=4000>>4000 gallons.\n",
        "The total amount of water in the first two tanks is 5250+4000 = <<5250+4000=9250>>9250 gallons.\n",
        "If Mr. Finnegan fills the third tank up to half its capacity, the tank fills up with 1/2*3000 = <<1500=1500>>1500 gallons.\n",
        "In total, the three tanks have 9250+1500 = <<9250+1500=10850>>10750 gallons of water.\n",
        "#### 10750\"\"\"\n",
        "}\n",
        "\n",
        "# Load the dataset once.\n",
        "dataset_openai = load_dataset(\"openai/gsm8k\", \"main\", split=\"train\")\n",
        "\n",
        "# Define a single update function that updates an example if its index is in the updates dict.\n",
        "def update_answers(example, idx):\n",
        "    if idx in updates:\n",
        "        example[\"answer\"] = updates[idx]\n",
        "    return example\n",
        "\n",
        "# Apply the update function to the dataset.\n",
        "dataset_openai = dataset_openai.map(update_answers, with_indices=True)\n",
        "\n",
        "# (Optional) Save the updated dataset to disk or push it to the Hugging Face Hub:\n",
        "dataset_openai.push_to_hub(\"niklasm222/gsm8k-prover\", token=\"\", private=False)\n"
      ],
      "metadata": {
        "id": "VG1PGDF20tJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232,
          "referenced_widgets": [
            "fa307be27890417b8882c647d628025a",
            "13ec1d46e476499fbdb870554e00e25d",
            "430de46fe1a74a25aa00e0be83364cb0",
            "0a1b003811c941d58b41d8debeaf580b",
            "68e9b35bb027444d8247f12a2e9423cc",
            "9bb06a1c301f4bd59778fc41ecdd1c90",
            "86817faaf2124a2281a0c82fda1edb93",
            "6c2d0d209090432ea913ba2a8e643e6b",
            "205b8e2cdab44610884bbde4478bac26",
            "5665cc36b136490e9fdc8e551f40d4b0",
            "893ddff3c99f49ffbf15ecd219024fe3",
            "ea7490993cfe4d4dbb414f099d7028fe",
            "ae21e1d597824ddfa62cd56a83a82a21",
            "2d9cac17a7b24515ba23b2a4d0de5276",
            "2b9ef576393643dea940ccaa251a1416",
            "83b9eacf65ba4174b7dc1ed51033fa40",
            "8f7ce5af02244b09b4153be6c0c3ae6a",
            "c2a7449833f2463298871a256482b43b",
            "552663931262451b9e9e204174608a81",
            "9f61e776b8e64ba1bcdc0b1542233e84",
            "7f32e5ee658d4d6688c3ec74ea36df03",
            "29b9d2e9da654b4ab42bd1a55e854dce",
            "2a7d12774d09439b96e65e13a7fc63cc",
            "03d5ee5aa43d4405a1cfa8d4629537ec",
            "27ac248d33de49d4be7d8eaa698dc0aa",
            "dff1749f219243beac2963349c431567",
            "c91b1d6789eb49b68501cea31cb35978",
            "5648a96e57624e0f87e23f17b26eb2fc",
            "74baf13c7a6b4da09000861a33014cb5",
            "2e7c464466aa48718096c56e19c7695c",
            "213706198868430d8af18b19000195fa",
            "e08f3b2ce848425b81884e98194c9923",
            "25cbd51e06a74ecba8b6fd14b0fbc79c",
            "fdc66d1eaaa8416ba92c7ed25e26c0a4",
            "de4b564ddc5545d7934b55350b39fb1e",
            "eda3e39f46a246ed948c7927f51148e3",
            "c19689fee9d143df922e68c0061ad747",
            "8a4069adadc446718d7b612628450414",
            "01a3f3dd56354bd08f6f991c26928161",
            "e423d21eeac34825a1209ecdee43f4a2",
            "112cc5cdd411457cbc007b7ff307d6db",
            "ff3dcc0d274949a88f0c2660af79f9f9",
            "f558f2f0066046c0bfc55dffd76a4c45",
            "7ba24f67266941e59b10d8f11bb1414b"
          ]
        },
        "outputId": "0cded39c-3202-4ede-d58d-d5c5248977c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa307be27890417b8882c647d628025a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea7490993cfe4d4dbb414f099d7028fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a7d12774d09439b96e65e13a7fc63cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdc66d1eaaa8416ba92c7ed25e26c0a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/niklasm222/gsm8k-prover/commit/e174834fc8175348d7474e3576129758b9d02001', commit_message='Upload dataset', commit_description='', oid='e174834fc8175348d7474e3576129758b9d02001', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/niklasm222/gsm8k-prover', endpoint='https://huggingface.co', repo_type='dataset', repo_id='niklasm222/gsm8k-prover'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Updates for indexes in gsm8k-prolog-prover"
      ],
      "metadata": {
        "id": "NHVZ_JnNHREI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index: 1983\n",
        "# Question: Janet buys 3 pounds of broccoli for $4 a pound, 3 oranges for $0.75 each, a cabbage for $3.75, a pound of bacon for $3, and two pounds of chicken for $3 a pound. What percentage of her grocery budget did she spend on meat, rounded to the nearest percent?\n",
        "# Extended Value: 33.33333333333333\n",
        "# OpenAI Value: 33.0\n",
        "# Difference: 0.3333333333333286\n",
        "\n",
        "# ----------------------\n",
        "# Define the new Prolog code to update the 'output' field for sample at index 1983.\n",
        "# ----------------------\n",
        "NEW_OUTPUT_TEXT_1983 = \"\"\":- use_module(library(clpq)).\n",
        ":- use_module(library(clpfd)).\n",
        "\n",
        "cost(broccoli, 3, 4).\n",
        "cost(oranges, 3, 0.75).\n",
        "cost(cabbage, 1, 3.75).\n",
        "cost(bacon, 1, 3).\n",
        "cost(chicken, 2, 3).\n",
        "\n",
        "percentage(Rounded_percentage) :-\n",
        "    Total_vegetable_cost is 3 * 4 + 3 * 0.75 + 3.75,\n",
        "    Total_meat_cost is 1 * 3 + 2 * 3,\n",
        "    Total_cost is Total_vegetable_cost + Total_meat_cost,\n",
        "    Percentage is (Total_meat_cost / Total_cost) * 100,\n",
        "    Rounded_percentage is round(Percentage).\n",
        "\n",
        "solve(Rounded_percentage) :-\n",
        "    percentage(Rounded_percentage).\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------\n",
        "# Load the GSM8K-Prolog-Extended dataset.\n",
        "# ----------------------\n",
        "dataset_extended = load_dataset(\"niklasm222/gsm8k-prolog-extended\", split=\"train\")\n",
        "\n",
        "# ----------------------\n",
        "# Define a function to update the output for sample at index 1983.\n",
        "# ----------------------\n",
        "def update_output(example, idx):\n",
        "    if idx == 1983:\n",
        "        example[\"output\"] = NEW_OUTPUT_TEXT_1983\n",
        "    return example\n",
        "\n",
        "# ----------------------\n",
        "# Update the dataset with the new output text.\n",
        "# ----------------------\n",
        "dataset_extended = dataset_extended.map(update_output, with_indices=True)\n",
        "\n",
        "# (Optional) Save the updated dataset to disk or push it to the Hugging Face Hub:\n",
        "dataset_extended.push_to_hub(\"niklasm222/gsm8k-prolog-prover\", token=\"\", private=False)\n"
      ],
      "metadata": {
        "id": "9vAmkzUWHTFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "d62d8993bbf14a65aac7ca31e0bda9a2",
            "0dab4eb3d4d04d92a2d21cc9605ee21e",
            "6c4db3b3e6bf4225819ab5b07307fa1d",
            "d886aa2a29d84cc0ad73fb6a78554699",
            "233e8db7afb1459d872c680c43d7db63",
            "9d6db9f01d144122bf9ba0d0ac24dd45",
            "1544919942e8486dacd4922fc2e2ccdf",
            "9677d7851db743dbbdae3d0f670244a8",
            "783f0c9dca9642ccbbf5caec30da5a56",
            "af6abedbfd77496cb49960cab9931439",
            "f6360a8868cb4f2cbba98ad07b9c9d9f",
            "0842a5189ffd459fb83dc75347fb0156",
            "d696805ccc2f4f018de31d88c26880ce",
            "5e1f48d88ba14790bcc89454659f15cb",
            "1520c401e897471fac75c57ddfac420d",
            "d577a4deb43f4553b1b201e2f4ffa611",
            "9399a07bcdcc43298839b92ea4a470df",
            "03937b3e6c5e4b578ca522e4d4b43777",
            "ac6f571100d441d98f952b1d017c9392",
            "847ce41ee7c24a8daa67a5b4fb2a59d5",
            "28f0156533454dc58979daf10e470a29",
            "7915ad63c32f4d12ad959faf522cba50",
            "f964153a42da45f8b44ab192737892d1",
            "dba5a22b52bd4da5a0808a2f5b49dfbf",
            "2b96587b156c48a1a2ab1aaa4018e607",
            "d91ddd4fca2d4cc6a4fc3dd2889f7f08",
            "6423d584b81e413c90400e88d1e24f4a",
            "8f3ac581af3d423bacfd020196f87d4e",
            "bf659d7b2f444d708a8f52c1d66f1fc0",
            "0b79414649d047b48974ee7aea9901a5",
            "af58d5f07a964dc599c952ba01482b0f",
            "e1578a8a3055469595b02ed57fc38f13",
            "f8ac078306ed4ffc86f611d1506f76e1",
            "1d722ebd5da94a838b22c1d09b7f686a",
            "1ece437327ab4f1cbcc145a6280cf9ee",
            "9d5ecddc61c24d2ba2e3e405680e0b5f",
            "17e6f735dc52436c9d270983a2a1fe0f",
            "5415bc8d4a8642b9b06190c9fb2d1943",
            "ede6b5d2fc164b12ba7fe4c3ea706090",
            "dedf4da15b544ea3b4d8b9f508ba9a86",
            "63d3fb4cc2cb4930acd21ea533faaf7e",
            "9eec970df37449a4b935be2172362388",
            "e25fcd73d63c4348a757bc03e1447161",
            "ed7cc51039f24050af833f67b0585311"
          ]
        },
        "outputId": "1644b769-755f-4173-a344-496971b74fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d62d8993bbf14a65aac7ca31e0bda9a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0842a5189ffd459fb83dc75347fb0156"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f964153a42da45f8b44ab192737892d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d722ebd5da94a838b22c1d09b7f686a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/niklasm222/gsm8k-prolog-prover/commit/9bc0e4716472a162edc52ef0038dddfddde153b5', commit_message='Upload dataset', commit_description='', oid='9bc0e4716472a162edc52ef0038dddfddde153b5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/niklasm222/gsm8k-prolog-prover', endpoint='https://huggingface.co', repo_type='dataset', repo_id='niklasm222/gsm8k-prolog-prover'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison after cleaning"
      ],
      "metadata": {
        "id": "9bHbWoV_RPKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import load_dataset\n",
        "\n",
        "# ----------------------\n",
        "# Helper Function to extract the final numeric answer from the OpenAI GSM8K \"answer\" column.\n",
        "# ----------------------\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    # Remove commas to facilitate conversion to float.\n",
        "    return text.split(\"####\")[1].replace(\",\", \"\").strip()\n",
        "\n",
        "# ----------------------\n",
        "# Load both datasets\n",
        "# ----------------------\n",
        "# Load gsm8k-prolog-extended dataset (change split as needed)\n",
        "dataset_extended = load_dataset(\"niklasm222/gsm8k-prolog-prover\", split=\"train\")\n",
        "# Load openai/gsm8k dataset (change split as needed)\n",
        "dataset_openai = load_dataset(\"niklasm222/gsm8k-prover\", split=\"train\")\n",
        "\n",
        "# Determine how many samples to compare (using the minimum length)\n",
        "total = min(len(dataset_extended), len(dataset_openai))\n",
        "\n",
        "# ----------------------\n",
        "# Compare numerical_result from gsm8k-prolog-extended with the numeric answer from openai/gsm8k\n",
        "# ----------------------\n",
        "matches = 0\n",
        "differences = []\n",
        "mismatches = []  # List to store mismatched sample details\n",
        "\n",
        "for i in range(total):\n",
        "    # Get the numerical_result from the gsm8k-prolog-extended dataset\n",
        "    ext_val_str = dataset_extended[i][\"numerical_result\"]\n",
        "    try:\n",
        "        ext_val = float(ext_val_str)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping sample {i} from extended dataset due to conversion error: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Get the answer text from the openai/gsm8k dataset\n",
        "    openai_answer_text = dataset_openai[i][\"answer\"]\n",
        "    extracted_str = extract_hash_answer(openai_answer_text)\n",
        "    if extracted_str is None:\n",
        "        print(f\"Skipping sample {i} from openai dataset because '####' not found.\")\n",
        "        continue\n",
        "    try:\n",
        "        openai_val = float(extracted_str)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping sample {i} from openai dataset due to conversion error: {e}\")\n",
        "        continue\n",
        "\n",
        "    diff = abs(ext_val - openai_val)\n",
        "    differences.append(diff)\n",
        "    if diff < 1e-6:\n",
        "        matches += 1\n",
        "    else:\n",
        "        # Record mismatched sample details: index, extended value, openai value, and optionally the question\n",
        "        question = dataset_extended[i].get(\"input\", \"N/A\")\n",
        "        mismatches.append({\n",
        "            \"index\": i,\n",
        "            \"question\": question,\n",
        "            \"extended_value\": ext_val,\n",
        "            \"openai_value\": openai_val,\n",
        "            \"difference\": diff\n",
        "        })\n",
        "\n",
        "accuracy = matches / total * 100\n",
        "print(f\"Compared {total} samples. Match accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "if mismatches:\n",
        "    print(\"\\nMismatched Samples:\")\n",
        "    for m in mismatches:\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"Index: {m['index']}\")\n",
        "        print(f\"Question: {m['question']}\")\n",
        "        print(f\"Extended Value: {m['extended_value']}\")\n",
        "        print(f\"OpenAI Value: {m['openai_value']}\")\n",
        "        print(f\"Difference: {m['difference']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "a288a35dc19541e9934396f320245bfa",
            "4395fffef1e646c1ab9b8708b3b7613a",
            "a96907ce6eec4d4a8edcb53a47f8262c",
            "d4baf21503c74b3492e68f2cdbe5eabe",
            "d7e9cd408f8745e192c8961c0935c76e",
            "a5d5221021c04ddeb2fc2f796557a661",
            "19f65ea7a32d478facb6b3d2632bad1a",
            "a779a3ccd8ad4b318ab22f5c21380252",
            "d60b71b188434112802bbaa9408d5bec",
            "5975622ea4f248be90f007417e5fff6c",
            "350de988dd7642be98a14b334c96c222",
            "3e2ecefe46af49b9be73672f7475ce1f",
            "90de5897c04f4076b4d60414866a5d8f",
            "057c42f49fe54ce7b8b33c3680fe3039",
            "bbede15802bc45a783fcbb65d067e26f",
            "083d983b18ba45abaac607db38d4e3b1",
            "3f714468c06a471d90caddd80ea5c587",
            "3918cd8d235d4d0e8d0642f778d6348c",
            "bdd0e873bffc4befbdf177f6032b09ce",
            "8d5ac189c8d849a48a34758d55aa18a9",
            "c30eff7494b54ed6b1a90a5c4f3f493d",
            "fda9eada4c3c413d94a163d7f3134e1d",
            "7fbf425b4a80491fb0fde4b502d07357",
            "f45da6171fb74e6c9a477a2d9776b5f1",
            "6152527f9dac47f8bfeaf1e2fff979a8",
            "d8a00edb2f3540f491fc138926b7e2c7",
            "0d9eb43861c8414e857227c7ef4ec30e",
            "57c8e170cd454212819f82049ab3774b",
            "a3cdf300679a4a86a8958598b99b91cb",
            "ac4fb965760b4ef18a90e6defe15bc67",
            "1857cf770de94bd38fe8c2e60da09b3f",
            "42b3c700855943639fcbc9b8008d298d",
            "4889808b74104560beba4f3a2397d219"
          ]
        },
        "id": "6vYrgQ4_RK3n",
        "outputId": "e8daa79e-aeee-4f03-f451-033b420676e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/536 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a288a35dc19541e9934396f320245bfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e2ecefe46af49b9be73672f7475ce1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fbf425b4a80491fb0fde4b502d07357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compared 7473 samples. Match accuracy: 100.00%\n"
          ]
        }
      ]
    }
  ]
}